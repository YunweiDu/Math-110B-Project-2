# Math-110B-Project-2
In the project, you will study the optimization algorithms related to the randomization. For a group of random algorithms, the randomness could be improved through certain strategy. Knowledge include stochastic gradient descent and randomized coordinate descent. When the ordering is sampled uniformly from  {1,2,…,m} , then this method becomes Stochastic GD. But the ordering could be other kind or distribution, even deterministic, we will mainly focus on select a better strategy for the ordering.
# Compile/Run the code
The first task comes from the Section 2.1 of the reference paper. It implement the 1D example of least square problem for the IGD. The second task comes from the Section 2.1 of the reference paper as well. Now instead of 1D problem considered in above two tasks, the third task will consider the general case in higher dimensions, it study the least square problem to find solution of Ax=y.
# Contributor
This project is based on reference paper "Beneath the valley of the noncommutative arithmetic-geometric mean inequality: conjectures, case-studies, and consequences" by Benjamin Recht and Christopher R´e, which evaluate the difference in performance between sampling with- and without-replacement in stochastic gradient descent and randomized coordinate descent.
##Group Member
Yunwei Du; Yining Dai; Wenyu Wu; Christy Lu
